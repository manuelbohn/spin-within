---
title: "Spin-within example data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)

library(tidyverse)
library(knitr)
library(ggthemes)
library(coda)
library(ggpubr)


estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

```

# Data

```{r}
data <- read_csv("../data/merged_data.csv")
```

* subid: subject id
* task: the three spin tasks `mutual_exclusivity`, `novelty`, `novelty`, `comprehension` and the two vocabulary tasks `comprehension` and `production`.
* trial: trial number within task.
* familiar: the familiar object involved (does not apply to `novelty`)
* correct: did the child pick the correct object (for `mutual_exclusivity`: did they pick the unfamiliar object).
* condition: combination only (`congruent` or `incongruent`).

# Model

The models differ in how we estimate the parameters for each individual. I think the main difference between them is that the second one is "pooling" more, that is, it is more heavily relying on the population level level estiamtes. Maybe that is why it generates more reliable (i.e. converging chains) estimates. 

## Gaussian model

This model uses an overall slope and intercept for a given parameter to compute the age specific parameter value. Here's the example. Within the `foreach(function(subject){` loop we first do

```{js}
var speakerOptimalitySample = speakerOptimalityParameters.intercept  + speakerOptimalityParameters.slope * meSubData[0].age
```

and then to get the subject specific estimate, we do: 

```{js}
var speakerOptimality = gaussianDrift({ mu: speakerOptimalitySample, sigma: speakerOptSigma, width: 0.1 })
```

Model file: `model/spin-within_model.wppl`

### Model output

```{r}
gauss_model <- readRDS("../model/output/model_run.rds")
```

#### Production probability

```{r}
gauss_model%>%
  filter(c == "successful_production_probability")%>%
  rename(value = f)%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  scale_fill_colorblind()+
  xlim(0,1)+
  theme_minimal()
```

#### Speaker optimality

##### Population

```{r}
gauss_model%>%
  filter(c == "speaker_optimality", 
         b != "parameters")%>%
  rename(parameter = b,
         value = f)%>%
  mutate(parameter = factor(parameter, levels = c("intercept", "slope", "sigma")))%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_grid(~parameter)+
  scale_fill_colorblind()+
  xlim(-4,4)+
  theme_minimal()
```
##### by subject

```{r}
gauss_model%>%
  rename(type = b,
         parameter = c,
         subject = e, 
         speaker_optimality = f)%>%
  filter(type != "sigma",
         parameter == "speaker_optimality")%>%
  ggplot(., aes(x = speaker_optimality, fill = chain))+
  geom_density(alpha = .5)+
  facet_wrap(subject~., scales = "free_y")+
  scale_fill_colorblind()+
  theme_minimal()
```

#### Semantic knowledge

##### Population

```{r}
gauss_model%>%
  filter(c == "semantic_knowledge", 
         b != "parameters")%>%
  rename(parameter = b,
         value = f)%>%
  mutate(parameter = factor(parameter, levels = c("intercept", "slope", "sigma")))%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_grid(~parameter)+
  scale_fill_colorblind()+
  xlim(-4,4)+
  theme_minimal()
```

##### by subject

This is for one of the items ('lock')

```{r}
gauss_model%>%
  rename(parameter = c,
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(familiar),
         parameter == "semantic_knowledge", 
         familiar == "lock")%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  ggtitle("Semantic knowledge for 'lock'")+
  facet_wrap(subject~., scales = "free_y")+
  scale_fill_colorblind()+
  theme_minimal()
```

For all items:

```{r}
gauss_model%>%
  rename(parameter = c,
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(familiar),
         !is.na(value),
         parameter == "semantic_knowledge")%>%
  group_by(subject, familiar,chain)%>%
    summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  ggplot(., aes(x = factor(subject), y= mode, col = chain))+
  geom_pointrange(aes(ymin = lci, ymax = uci), position = position_dodge(width = .1), pch = 4)+
  scale_color_colorblind()+
  facet_grid(familiar~.)+
  theme_few()
```
#### Prior

##### Population

```{r}
gauss_model%>%
  filter(c == "prior", 
         b != "parameters")%>%
  rename(parameter = b,
         value = f)%>%
  mutate(parameter = factor(parameter, levels = c("intercept", "slope", "sigma")))%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_grid(~parameter)+
  scale_fill_colorblind()+
  xlim(-4,4)+
  theme_minimal()
```

##### by subject

```{r}
gauss_model%>%
  rename(parameter = c, 
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(subject),
         parameter == "prior")%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_wrap(subject~., scales = "free_y")+
  scale_fill_colorblind()+
  xlim(0,1)+
  theme_minimal()

```

## Age based competence model

For this model, the individual estimates are not based not on a Gaussian around the age specific value but calculated by sampling a different "age" for each subject an use this to compute the subject specific estimate. So we start with: 

```{js}
var speakerOptimalitySample = gaussianDrift({ mu: meSubData[0].age, sigma: speakerOptSigma, width: 0.1 })
```

and then do

```{js}
var speakerOptimality = speakerOptimalityParameters.intercept  + speakerOptimalityParameters.slope * speakerOptimalitySample
```

The individual estimates are more or less different points along the population level regression line. 

Model file: `model/spin-within_model_item_slopes.wppl`

### Model output

```{r}
comp_model <- readRDS("../model/output/model_run_item_slopes.rds")
```

#### Production probability

```{r}
comp_model%>%
  filter(c == "successful_production_probability")%>%
  rename(value = f)%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  scale_fill_colorblind()+
  xlim(0,1)+
  theme_minimal()
```

#### Speaker optimality

##### Population

```{r}
comp_model%>%
  filter(c == "speaker_optimality", 
         b != "parameters")%>%
  rename(parameter = b,
         value = f)%>%
  mutate(parameter = factor(parameter, levels = c("intercept", "slope", "sigma")))%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_grid(~parameter)+
  scale_fill_colorblind()+
  xlim(-4,4)+
  theme_minimal()
```

##### by subject

```{r}
comp_model%>%
  rename(type = b,
         parameter = c,
         subject = e, 
         speaker_optimality = f)%>%
  filter(type != "sigma",
         parameter == "speaker_optimality")%>%
  ggplot(., aes(x = speaker_optimality, fill = chain))+
  geom_density(alpha = .5)+
  facet_wrap(subject~., scales = "free_y")+
  scale_fill_colorblind()+
  theme_minimal()
```

#### Semantic knowledge

##### Population

```{r}
comp_model%>%
  filter(c == "semantic_knowledge", 
         b != "parameters")%>%
  rename(parameter = b,
         value = f)%>%
  mutate(parameter = factor(parameter, levels = c("intercept", "slope", "sigma")))%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_grid(~parameter)+
  scale_fill_colorblind()+
  xlim(-4,4)+
  theme_minimal()
```

##### by subject

This is for one of the items ('lock')

```{r}
comp_model%>%
  rename(parameter = c,
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(familiar),
         parameter == "semantic_knowledge", 
         familiar == "lock")%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  ggtitle("Semantic knowledge for 'lock'")+
  facet_wrap(subject~., scales = "free_y")+
  scale_fill_colorblind()+
  theme_minimal()
```

For all items:

```{r}
comp_model%>%
  rename(parameter = c,
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(familiar),
         !is.na(value),
         parameter == "semantic_knowledge",
         subject != "NA")%>%
  group_by(subject, familiar,chain)%>%
    summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  ggplot(., aes(x = factor(subject), y= mode, col = chain))+
  geom_pointrange(aes(ymin = lci, ymax = uci), position = position_dodge(width = .1), pch = 4)+
  scale_color_colorblind()+
  facet_grid(familiar~.)+
  theme_few()

```

#### Prior

##### Population

```{r}
comp_model%>%
  filter(c == "prior", 
         b != "parameters")%>%
  rename(parameter = b,
         value = f)%>%
  mutate(parameter = factor(parameter, levels = c("intercept", "slope", "sigma")))%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_grid(~parameter)+
  scale_fill_colorblind()+
  xlim(-4,4)+
  theme_minimal()
```

##### by subject

```{r}
comp_model%>%
  rename(parameter = c, 
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(subject),
         parameter == "prior")%>%
  ggplot(., aes(x = value, fill = chain))+
  geom_density(alpha = .5)+
  facet_wrap(subject~., scales = "free_y")+
  scale_fill_colorblind()+
  xlim(0,1)+
  theme_minimal()

```

## Relations between models and data

Here are some simple correlations between the model estimates and the data.

### Speaker Optimality and ME Data

There shouldn't be a 1:1 correspondence (i.e. very high correlation) because the ME task also -- and critically -- involves semantic knowledge

```{r}
sgm <- gauss_model%>%
  rename(type = b,
         parameter = c,
         subject = e, 
         value = f)%>%
  filter(type != "sigma",
         parameter == "speaker_optimality")%>%
  mutate(subject = factor(subject))%>%
  group_by(subject)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  mutate(model = "gaussian")

scm <- comp_model%>%
  rename(type = b,
         parameter = c,
         subject = e, 
         value = f)%>%
  filter(type != "sigma",
         parameter == "speaker_optimality")%>%
  mutate(subject = factor(subject))%>%
  group_by(subject)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  mutate(model = "competence")

sd <- data%>%
  filter(task == "mutual_exclusivity")%>%
    mutate(subject = factor(subid))%>%
    group_by(subject)%>%
    summarise(data_mean = mean(correct))%>%
  filter(!is.na(data_mean))

bind_rows(
  sgm%>%left_join(sd),
  scm%>%left_join(sd)
)%>%
  ggplot(aes(x = mode, y = data_mean))+
  geom_point(alpha = .5)+
  stat_cor(method = "pearson", label.x = 0.01, label.y = 0.99, aes(x = mode, y = data_mean, label = paste(..r.label..)), inherit.aes = F, size = 4, r.accuracy = 0.01, cor.coef.name = "r")+
  facet_grid(~model)+
  theme_minimal()+
  geom_smooth(method = "lm", se = F, col = "black")+
  ylim(0,1)
```

### Semantic knowledge and comprehension / production data

Note that the model estimates also take in the ME data

```{r}
semgm <- gauss_model%>%
  rename(parameter = c,
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(familiar),
         !is.na(value),
         parameter == "semantic_knowledge")%>%
  mutate(subject = factor(subject))%>%
  group_by(familiar, subject)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  mutate(model = "gaussian")

semcm <- comp_model%>%
  rename(parameter = c,
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(familiar),
         !is.na(value),
         parameter == "semantic_knowledge")%>%
  mutate(subject = factor(subject))%>%
  group_by(familiar, subject)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  mutate(model = "competence")

semd <- data%>%
  filter(task == "comprehension" | task == "production" 
         #| task == "mutual_exclusivity"
         )%>%
    mutate(subject = factor(subid))%>%
    group_by(familiar,subject)%>%
    summarise(data_mean = mean(correct))

bind_rows(
  semgm%>%left_join(semd),
  semcm%>%left_join(semd)
)%>%
  ggplot(aes(x = mode, y = data_mean))+
    geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .5)+
  geom_point(alpha = .5)+
  stat_cor(method = "pearson", label.x = 0.01, label.y = 0.99, aes(x = mode, y = data_mean, label = paste(..r.label..)), inherit.aes = F, size = 4, r.accuracy = 0.01, cor.coef.name = "r")+
  facet_grid(~model)+
  theme_minimal()+
  ylim(0,1)+
  xlim(0,1)
```

### Prior

Here we have a pretty good 1:1 correspondence and should see high correlations. 

```{r}
pgm <- gauss_model%>%
  rename(parameter = c, 
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(subject),
         parameter == "prior")%>%
  mutate(subject = factor(subject))%>%
  group_by(subject)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  mutate(model = "gaussian")

pcm <- comp_model%>%
  rename(parameter = c, 
         familiar = d, 
         subject = e, 
         value = f)%>%
  filter(!is.na(subject),
         parameter == "prior")%>%
  mutate(subject = factor(subject))%>%
  group_by(subject)%>%
  summarise(mode = estimate_mode(value),
            lci = hdi_lower(value),
            uci = hdi_upper(value))%>%
  mutate(model = "competence")

pd <- data%>%
    filter(task == "novelty")%>%
    mutate(subject = factor(subid))%>%
    group_by(subject)%>%
    summarise(data_mean = mean(correct))%>%
  filter(!is.na(data_mean))

bind_rows(
  pgm%>%left_join(pd),
  pcm%>%left_join(pd)
)%>%
  ggplot(aes(x = mode, y = data_mean))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = .5)+
  geom_point(alpha = .5)+
  stat_cor(method = "pearson", label.x = 0.01, label.y = 0.99, aes(x = mode, y = data_mean, label = paste(..r.label..)), inherit.aes = F, size = 4, r.accuracy = 0.01, cor.coef.name = "r")+
  facet_grid(~model)+
  theme_minimal()+
  ylim(0,1)+
  xlim(0,1)
    
```

## Summary

The "competence" model estimates seem to be a) more stable (i.e. chains converge better) and b) closer to the data. 

Open questions / things unclear to me: 

* Estimates from the Gaussian model for semantic knowledge seem to be restricted to values above ~0.5? 

# Reminder: Tasks

We use the same tasks as in Spin, that is:
 
* Mutual Exclusivity
* Novelty
* Combination

In addition, we have two new vocabulary tasks:

* Production
* Comprehension

Across all tasks (except novelty of course) we use a total of 16 familiar objects. There is one trial for each familiar object in mutual exclusivity, production and comprehension. There are also 16 trials in combination, half of which are congruent and the other half are incongruent.

Production and comprehension task are run after the other three.

## Production

For the production task, the experimenter shows the child a picture of an object (the same as is used in the other experiments) and asks:"Can you tell me what this is?" The trial is coded as correct, if the child sys the correct word (or a word from a pre-specified list of synonyms). The experimenter goes through each of the 16 objects one by one.

Picture below shows an example.

```{r}
knitr::include_graphics("../documentation/production_task_example_pic.png")
```

## Comprehension task

The child is shown 6 objects on a screen, 4 of which are objects that appeared in the rest of the study and 2 are distractors The experimenter asks the child to pick out an object (e.g. "can you point to the lock?") and the child responds by selecting one of the objects. 

We code as correct if the child clikcs on the correct object OR if they named the object during production.

The experimenter goes through all 16 familiar objects on a total of 4 slides (each showing 6 objects, including 2 distractors).

Picture below shows an example (familiar objects from the study: rasp, lock, apple, hange; distractors: dog toy and hydrant).

```{r}
knitr::include_graphics("../documentation/comprehension_task_example_pic.png")
```



