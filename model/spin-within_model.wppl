// example call: time webppl spin-within_model.wppl --require webppl-json --require webppl-sample-writer 1

var chain = last(process.argv)

var all_objects = [
  { shape: "novel_object"},
  { shape: "familiar_object"}
]

var labels = ["novel_word","familiar_word"]


var lexicon1 = function(utterance, obj, sem_knowledge){
  utterance.label == "novel_word" ? obj.shape == "novel_object" :
  utterance.label == "familiar_word" ? flip(sem_knowledge) ?
  obj.shape == "familiar_object" :
  flip() ? obj.shape == "familiar_object" : obj.shape == "novel_object" :
  true
}

var lexicon2 = function(utterance, obj, sem_knowledge){
  utterance.label == "novel_word" ? obj.shape == "familiar_object" :
  utterance.label == "familiar_word" ? flip(sem_knowledge) ?
  obj.shape == "familiar_object" :
  flip() ? obj.shape == "familiar_object" : obj.shape == "novel_object" :
  true
}

var lexiconObjects = {
  "novel_word = novel_object": {
    novel_object: "novel_word", familiar_object: "familiar_word"
  },
  "novel_word = familiar_object": {
    novel_object: "familiar_word", familiar_object: "familiar_word"
  },
}

var lexiconObject = {
  "novel_word = novel_object": lexicon1,
  "novel_word = familiar_object" : lexicon2
}

var utterancePrior = function(){ return uniformDraw([ {label: "novel_word"}, {label: "familiar_word"}]) }

var LexiconPrior = Categorical({vs: ["novel_word = novel_object","novel_word = familiar_object" ], ps: [1, 1]})

var foreach = function(fn, lst) {
  var foreach_ = function(i) {
    if (i < lst.length) {
      fn(lst[i]);
      foreach_(i + 1);
    }
  };
  foreach_(0);
};

var logistic = function(x) {1 / (1 + Math.exp(-x))}

var levels = function(df, label){
  return _.uniq(_.map(df, label));
}

//////////////// Data //////////////

var data = json.read('../data/merged_data.json');

var priorData = _.filter(data, {task: "novelty"})
var meData = _.filter(data, {task: "mutual_exclusivity"})
var comprehensionData = _.filter(data, {task: "comprehension"})
var prodData = _.filter(data, {task: "production"})

// var combData = json.read('../data/combination.json');

var familiars = levels(meData, "familiar")

var subjects = levels(data, "subid")

var model  = function(){

  ////////////// Prior ////////////////////////

  var prior_slope = uniformDrift({
    a: -2,
    b: 2,
    width: 0.1
  })
  var prior_int = uniformDrift({
    a: 0,
    b: 2,
    width: 0.1
  })

  var priorSigma = uniformDrift({a: 0, b:1, width: 0.1})

  foreach(function(subject){

    var priorSubjectData = _.filter(priorData, {subid: subject})

    var priorSubjectData_correct = _.map(priorSubjectData, "correct")

    var priorAge = prior_int + prior_slope * priorSubjectData[0].age

    var priorSample = gaussianDrift({mu: priorAge, sigma: priorSigma, width: 0.1})

    var priorReg = logistic(priorSample)

    var prior = [priorReg, 1 - priorReg]

    var priorModel = Infer({method: "enumerate", model: function(){
      var obj = sample( Categorical({vs: all_objects, ps: prior}));
      return obj.shape == "novel_object" ? 1 : 0
    }})

    mapData({data: priorSubjectData_correct}, function(d){
      // display("prior for subject = " + subject + " score = " + priorModel.score(d))
      observe(priorModel, d);
    })

    query.add(["parameter","parameters", "prior", "NA", subject], priorReg)

  }, subjects)


  query.add(["parameter","sigma","prior", "NA", "NA"], priorSigma)
  query.add(["parameter","intercept","prior", "NA", "NA"], prior_int)
  query.add(["parameter","slope","prior", "NA", "NA"], prior_slope)

  //////////////// Semantic knowledge and speaker optimality ////////////////////////

  var speakerOptimalityParameters = {
    intercept: uniformDrift({
      a: 0,
      b: 3,
      width: 0.1
    }),
    slope: uniformDrift({
      a: 0,
      b: 3,
      width: 0.1
    })
  }

  var speakerOptSigma = uniformDrift({
    a: 0,
    b: 1,
    width: 0.1
  })

  var sampleSpeakerOptimality = function(so){
   var x =  gaussianDrift({ mu: so, sigma: speakerOptSigma, width: 0.1 })
   //return x < 0.001 ? 0.001 : x
   return x < 0 ? sampleSpeakerOptimality(so) : x
 }

  var successfulProductionProbability = uniformDrift({a:0.5, b:1, width: 0.1})
  var randomProductionProbability = 0 // uniformDrift({a:0, b:0.2, width: 0.05})
  var successfulSelectionProbability = 1 // could also be a parameter like successfulProductionProbability


  var sem_know_slope = uniformDrift({
    a: 0,
    b: 2,
    width: 0.1
  })
  var sem_know_int = uniformDrift({
    a: -2,
    b: 2,
    width: 0.1
  })

  var semKnowSigma = uniformDrift({a: 0, b:1, width: 0.1})


  foreach(function(subject){

    var meSubData = _.filter(meData, {subid: subject})
    var comprehensionSubData = _.filter(comprehensionData, {subid: subject})
    var prodSubData = _.filter(prodData, {subid: subject})

    var speakerOptimalitySample = speakerOptimalityParameters.intercept  + speakerOptimalityParameters.slope * meSubData[0].age
    var speakerOptimality = sampleSpeakerOptimality(speakerOptimalitySample)

    foreach(function(familiar){

      var meSubItemData = _.filter(meSubData, {familiar: familiar})
      var comprehensionSubItemData = _.filter(comprehensionSubData, {familiar: familiar})
      var prodSubItemData = _.filter(prodSubData, {familiar: familiar})


      var semKnowAge = sem_know_int + sem_know_slope * meSubItemData[0].age
      var semKnowSample = gaussianDrift({mu: semKnowAge, sigma: semKnowSigma, width: 0.1})
      var sem_knowledge = logistic(semKnowSample)

        var productionModel = Infer({method: "enumerate", model: function(){
            var knowsWord = flip(sem_knowledge)
            var correctWord = knowsWord ?
              flip(successfulProductionProbability) : // could be 1
              flip(randomProductionProbability) // very small
            return correctWord ? 1 : 0
          }
        })

        // display(JSON.stringify(productionModel))
        // display(prodSubItemData)
        // display(familiar)
        // display("production for subject = " + subject + " familiar = " + familiar + " score = " + productionModel.score(prodSubItemData[0]["correct"]))

        observe(productionModel, prodSubItemData[0]["correct"])

        var comprehensionModel = Infer({method: "enumerate", model: function(){
          var knowsWord = flip(sem_knowledge)
          var correctRef = knowsWord ?
            flip(successfulSelectionProbability) : // could be 1
            flip(1/6)
          return correctRef ? 1 : 0
          }
        })

        // display(JSON.stringify(comprehensionModel))
        // display(comprehensionSubItemData)
        // display("comprehension for subject = " + subject + " familiar = " + familiar + " score = " + comprehensionModel.score(comprehensionSubItemData[0]["correct"]))

        observe(comprehensionModel, comprehensionSubItemData[0]["correct"])

        var literalListener = cache(function(utterance){
          Infer({method: "enumerate", model: function(){
            var lexiconName = sample(LexiconPrior);
            var lexicon = lexiconObject[lexiconName];
            var obj = sample( Categorical({vs: all_objects, ps: [.5,.5]}));
            if ("label" in utterance) {
              var truthValue = lexicon(utterance, obj, sem_knowledge);
              condition(truthValue)
            }
            return obj.shape
          }})}, 10000)

          var speaker = cache(function(obj, lexiconName){
            Infer({method: "enumerate", model: function(){
              var utterance = utterancePrior();
              var L0 = literalListener(utterance);
              factor(speakerOptimality * L0.score(obj.shape))
              return utterance
            }})}, 10000)

            var pragmaticListener = function(utterance){
              Infer({method: "enumerate", model: function(){
                var lexiconName = sample(LexiconPrior);
                var obj = sample( Categorical({vs: all_objects, ps: [.5,.5]}));
                var S1 = speaker(obj, lexiconName);
                observe(S1, utterance)
                return obj.shape == "novel_object" ? 1 : 0
              }})}

              var meModel = pragmaticListener({label: "novel_word"})

              //display("ME for subject = " + subject + " familiar = " + familiar + " score = " + meModel.score(meSubItemData[0]["correct"]))

              observe(meModel, meSubItemData[0]["correct"])

            query.add(["parameter","parameters","semantic_knowledge", familiar, subject], sem_knowledge)

            }, familiars)

            query.add(["parameter","parameters","speaker_optimality", "NA", subject], speakerOptimality)

          }, subjects)


            query.add(["parameter","sigma","speaker_optimality", "NA", "NA"], speakerOptSigma)
            query.add(["parameter","intercept","speaker_optimality", "NA", "NA"], speakerOptimalityParameters.intercept)
            query.add(["parameter","slope","speaker_optimality", "NA", "NA"], speakerOptimalityParameters.slope)

            query.add(["parameter","sigma","semantic_knowledge", "NA", "NA"], semKnowSigma)
            query.add(["parameter","intercept","semantic_knowledge", "NA", "NA"], sem_know_int)
            query.add(["parameter","slope","semantic_knowledge", "NA", "NA"], sem_know_slope)

            query.add(["parameter","parameters","successful_production_probability", "NA", "NA"], successfulProductionProbability)

          //////////////// Model predictions and combination ////////////////////////

          // foreach(function(age_month) {
          //
          //   var combData_byAge = _.filter(combData, {age_month: age_month})
          //
          //   var priorReg = logistic(prior_int + prior_slope * age_month)
          //
          //   var global_sem_knowledge = logistic(globalLineParameters.intercept +
          //     globalLineParameters.slope * age_month)
          //
          //     var speakerOptimality = speakerOptimalityParameters.intercept  +
          //     speakerOptimalityParameters.slope * age_month
          //
          //     foreach(function(item){
          //
          //       var itemLineParameters = all_item_parameters[item]
          //       var item_sem_knowledge = logistic(itemLineParameters.intercept +
          //         itemLineParameters.slope * age_month)
          //
          //
          //         foreach(function(alignment_condition){
          //
          //           var priorComb = (alignment_condition == "congruent") ? [priorReg, 1 - priorReg] : [1 - priorReg, priorReg]
          //
          //           foreach(function(model_type){
          //
          //             var sem_knowledge = (model_type == "global") ? global_sem_knowledge : item_sem_knowledge
          //             var priorProbs = (model_type == "flat") ? [0.5, 0.5] : priorComb
          //
          //             var literalListener = cache(function(utterance){
          //               Infer({method: "enumerate", model: function(){
          //                 var lexiconName = sample(LexiconPrior);
          //                 var lexicon = lexiconObject[lexiconName];
          //                 var obj = sample( Categorical({vs: all_objects, ps: [.5,.5]}));
          //                 if ("label" in utterance) {
          //                   var truthValue = lexicon(utterance, obj, sem_knowledge);
          //                   condition(truthValue)
          //                 }
          //                 return obj.shape
          //               }})
          //             }, 10000)
          //
          //             var speaker = cache(function(obj, lexiconName){
          //               Infer({method: "enumerate", model: function(){
          //                 var utterance = utterancePrior();
          //                 var L0 = literalListener(utterance);
          //                 factor(speakerOptimality * L0.score(obj.shape))
          //                 return utterance
          //               }})
          //             }, 10000)
          //
          //             var pragmaticListener = function(utterance){
          //               Infer({method: "enumerate", model: function(){
          //                 var lexiconName = sample(LexiconPrior);
          //                 var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
          //                 var S1 = speaker(obj, lexiconName);
          //                 observe(S1, utterance)
          //                 return obj.shape == "novel_object" ? 1 : 0
          //               }})
          //             }
          //
          //             var modelPredictions = pragmaticListener({label: "novel_word"})
          //
          //             query.add(["modelPrediction",model_type,"free", alignment_condition, item, age_month], Math.exp(modelPredictions.score(1)))
          //
          //           }, ["pragmatic", "global", "flat"])
          //
          //           var priorOnlyModelPredictions = Infer({method: "enumerate", model: function(){
          //             var obj = sample( Categorical({vs: all_objects, ps: priorComb}));
          //             return obj.shape == "novel_object" ? 1 : 0
          //           }})
          //
          //           query.add(["modelPrediction","prior","free", alignment_condition, item, age_month], Math.exp(priorOnlyModelPredictions.score(1)))
          //
          //         }, ["congruent", "incongruent"])
          //
          //       }, familiars)
          //
          //     }, combDataAges)
          //
          //     foreach(function(item){
          //       var itemLineParameters = all_item_parameters[item]
          //       query.add(["parameter","items", item, "intercept", "NA", "NA"], itemLineParameters.intercept)
          //       query.add(["parameter","items", item, "slope", "NA", "NA"], itemLineParameters.slope)
          //     }, familiars)
          //
        //     query.add(["parameter","parameters", "global_sem", "intercept", "NA", "NA"], globalLineParameters.intercept)
          //     query.add(["parameter","parameters", "global_sem", "slope", "NA", "NA"], globalLineParameters.slope)
          //     query.add(["parameter","sigma", "global_sem_sigmas", "intercept", "NA", "NA"], itemVariability.intercept)
          //     query.add(["parameter","sigma", "global_sem_sigmas", "slope", "NA", "NA"], itemVariability.slope)
              return query
            }


            var header = "iteration,a,b,c,d,e,f,g,h"

            var lag = 4

            var samples = 10000;

            var burn = 50000;

            var output_file = 'output/spin-within_model-'+ samples+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv'
            var callback = webpplSampleWriter.streamQueryCSV(output_file, header);

            var output  = Infer({model,
              samples: samples,
              burn: burn,
              lag: lag,
              verbose: true,
              method: 'MCMC',
              onlyMAP: true,
              callbacks: [callback]
            });

            'output written to ' + output_file
